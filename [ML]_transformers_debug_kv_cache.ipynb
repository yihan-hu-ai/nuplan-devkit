{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yihan-hu-ai/nuplan-devkit/blob/master/%5BML%5D_transformers_debug_kv_cache.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rd30Xbe7LDzi"
      },
      "source": [
        "\n",
        "\n",
        "<a title=\"By Josef Steppan [CC BY-SA 4.0 (https://creativecommons.org/licenses/by-sa/4.0)], from Wikimedia Commons\" href=\"https://commons.wikimedia.org/wiki/File:MnistExamples.png\"><img width=\"512\" alt=\"MnistExamples\" src=\"https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJbSw2_0tmZQ"
      },
      "source": [
        "# **Task Overview: Image Generation with Autoregessive Transformers**\n",
        "\n",
        "## Primary Task\n",
        "\n",
        "\t1.\tFix Bugs in Transformers\n",
        "\t  •\tIdentify and resolve approximately 5 bugs.\n",
        "\t2.\tOptimize Training Loss and Quality\n",
        "    •\tEnsure the training loss is below 2.8.\n",
        "    •\tAchieve reasonable image generation quality.\n",
        "\n",
        "## Several follow-up afterwards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9q6Is9fdLDzj",
        "outputId": "26bffac5-c55d-4ef9-ca45-57d4ad3e1836"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUhLSPRaLDzk"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwHSpga0FIfI"
      },
      "source": [
        "Let's load the MNIST Dataset!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "id__E0DVtmzc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "class CustomMNIST(MNIST):\n",
        "    \"\"\"\n",
        "    MNIST dataset that downloads from a custom GitHub mirror.\n",
        "    \"\"\"\n",
        "\n",
        "    # Override the mirrors with the raw GitHub URLs\n",
        "    mirrors = [\n",
        "        \"https://raw.githubusercontent.com/mkolod/MNIST/master/\"  # Custom mirror URL\n",
        "    ]\n",
        "\n",
        "    # Keep the same resource filenames and MD5 checksums\n",
        "    resources = [\n",
        "        (\"train-images-idx3-ubyte.gz\", \"f68b3c2dcbeaaa9fbdd348bbdeb94873\"),\n",
        "        (\"train-labels-idx1-ubyte.gz\", \"d53e105ee54ea40749a09fcbcd1e9432\"),\n",
        "        (\"t10k-images-idx3-ubyte.gz\", \"9fb629c4189551a2d022fa330f9573f3\"),\n",
        "        (\"t10k-labels-idx1-ubyte.gz\", \"ec29112dd5afa0611ce80d1b7f02629c\"),\n",
        "    ]\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        root: str,\n",
        "        train: bool = True,\n",
        "        transform=None,\n",
        "        target_transform=None,\n",
        "        download: bool = False,\n",
        "    ):\n",
        "        super().__init__(\n",
        "            root=root,\n",
        "            train=train,\n",
        "            transform=transform,\n",
        "            target_transform=target_transform,\n",
        "            download=download,\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2WpPRDaLDzm"
      },
      "outputs": [],
      "source": [
        "class MNISTSequenceDataset(Dataset):\n",
        "    def __init__(self, train=True, data_dir='../data', samples_per_class=100):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            train (bool): Whether to load the training set.\n",
        "            data_dir (str): Directory where MNIST data is stored/downloaded.\n",
        "            samples_per_class (int): Number of samples per class in training mode.\n",
        "        \"\"\"\n",
        "        self.dataset = CustomMNIST(\n",
        "            root=data_dir,\n",
        "            train=train,\n",
        "            download=True,  # Downloads from the custom mirror\n",
        "            transform=transforms.Compose([\n",
        "                transforms.Resize((7, 7)),  # Resize images to 7x7\n",
        "                transforms.ToTensor()\n",
        "            ])\n",
        "        )\n",
        "\n",
        "        if train:\n",
        "            # Subsample the dataset to `samples_per_class` samples per class\n",
        "            targets = self.dataset.targets\n",
        "            num_classes = 10\n",
        "            samples_per_class = samples_per_class  # Number of samples per class\n",
        "            indices = []\n",
        "            for c in range(num_classes):\n",
        "                # Get indices of all samples belonging to class c\n",
        "                class_indices = (targets == c).nonzero(as_tuple=False).view(-1)\n",
        "                # Select the first 'samples_per_class' indices\n",
        "                class_indices = class_indices[:samples_per_class]\n",
        "                indices.extend(class_indices.tolist())\n",
        "            self.indices = indices\n",
        "        else:\n",
        "            # For the test set, use the full set\n",
        "            self.indices = list(range(len(self.dataset)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        real_idx = self.indices[idx]\n",
        "        img, _ = self.dataset[real_idx]\n",
        "        img = img.view(-1)            # Flatten image to (7*7,)\n",
        "        img = (img * 255).long()      # Scale pixel values to 0-255 and convert to long\n",
        "        return img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AWdtUsbFTaH"
      },
      "source": [
        "Let's Build the model! There will be total 5 bugs after the block."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMQdz2eNLDzm"
      },
      "outputs": [],
      "source": [
        "class SimpleGPT(nn.Module):\n",
        "    def __init__(self, vocab_size=256, max_seq_len=49, embedding_dim=128, num_heads=4, num_layers=4, dropout=0.1):\n",
        "        super(SimpleGPT, self).__init__()\n",
        "        self.token_embedding = nn.Parameter(torch.zeros(vocab_size, embedding_dim))\n",
        "        self.layers = nn.ModuleList([\n",
        "            TransformerBlock(embedding_dim, num_heads, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "        self.ln_f = nn.LayerNorm(embedding_dim)\n",
        "        self.head = nn.Linear(embedding_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len = x.size()\n",
        "        x = self.token_embedding[x]\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        x = self.ln_f(x)\n",
        "        logits = self.head(x)\n",
        "        return logits\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, embedding_dim, num_heads, dropout):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.attn = MaskedMultiHeadSelfAttention(embedding_dim, num_heads, dropout)\n",
        "        self.ln1 = nn.LayerNorm(embedding_dim)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(embedding_dim, 4 * embedding_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(4 * embedding_dim, embedding_dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "        self.ln2 = nn.LayerNorm(embedding_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.ln1(x))\n",
        "        x = x + self.mlp(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "class MaskedMultiHeadSelfAttention(nn.Module):\n",
        "    def __init__(self, embedding_dim, num_heads, dropout):\n",
        "        super(MaskedMultiHeadSelfAttention, self).__init__()\n",
        "        assert embedding_dim % num_heads == 0\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = embedding_dim // num_heads\n",
        "        self.scale = self.head_dim ** -0.5\n",
        "\n",
        "        # Separate projections for Q, K, V\n",
        "        self.q_proj = nn.Linear(embedding_dim, embedding_dim)\n",
        "        self.k_proj = nn.Linear(embedding_dim, embedding_dim)\n",
        "        self.v_proj = nn.Linear(embedding_dim, embedding_dim)\n",
        "        self.out_proj = nn.Linear(embedding_dim, embedding_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len, embedding_dim = x.size()\n",
        "\n",
        "        # Project inputs to Q, K, V\n",
        "        q = self.q_proj(x)\n",
        "        k = self.k_proj(x)\n",
        "        v = self.v_proj(x)\n",
        "\n",
        "        # Reshape and transpose for multi-head attention\n",
        "        q = q.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        k = k.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        v = v.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        attn_weights = torch.matmul(q, k.transpose(-2, -1)) * self.scale\n",
        "\n",
        "        # Apply attention mask\n",
        "        attn_weights = self.apply_mask(attn_weights)\n",
        "\n",
        "        # Softmax and dropout\n",
        "        attn_probs = torch.softmax(attn_weights, dim=-1)\n",
        "        attn_probs = self.dropout(attn_probs)\n",
        "\n",
        "        # Compute attention output\n",
        "        attn_output = torch.matmul(attn_probs, q)\n",
        "        attn_output = attn_output.transpose(1, 2).contiguous().view(batch_size, seq_len, embedding_dim)\n",
        "        output = self.out_proj(attn_output)\n",
        "        return output\n",
        "\n",
        "    def apply_mask(self, attn_weights):\n",
        "        batch_size, num_heads, seq_len_q, seq_len_k = attn_weights.size()\n",
        "        device = attn_weights.device\n",
        "        mask = torch.triu(torch.ones(seq_len_q, seq_len_k, device=device), diagonal=1).bool()\n",
        "        attn_weights = attn_weights.masked_fill(mask.unsqueeze(0).unsqueeze(0), float('inf'))\n",
        "        return attn_weights\n",
        "\n",
        "# Training Code\n",
        "def train(model, dataloader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in dataloader:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(batch[:, 1:])\n",
        "        loss = criterion(logits.reshape(-1, logits.size(-1)), batch[:, 1:].reshape(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxXUiGT2FebM"
      },
      "source": [
        "All the bugs exist in the block above!\n",
        "\n",
        "Let's Train the model! The correct code should get the loss below 2.8."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0POId6CSupKM",
        "outputId": "a7af63a5-b5ad-4b76-9472-a9080320c677"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://raw.githubusercontent.com/mkolod/MNIST/master/train-images-idx3-ubyte.gz\n",
            "Downloading https://raw.githubusercontent.com/mkolod/MNIST/master/train-images-idx3-ubyte.gz to ../data/CustomMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 110MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ../data/CustomMNIST/raw/train-images-idx3-ubyte.gz to ../data/CustomMNIST/raw\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading https://raw.githubusercontent.com/mkolod/MNIST/master/train-labels-idx1-ubyte.gz\n",
            "Downloading https://raw.githubusercontent.com/mkolod/MNIST/master/train-labels-idx1-ubyte.gz to ../data/CustomMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 3.83MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ../data/CustomMNIST/raw/train-labels-idx1-ubyte.gz to ../data/CustomMNIST/raw\n",
            "\n",
            "Downloading https://raw.githubusercontent.com/mkolod/MNIST/master/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://raw.githubusercontent.com/mkolod/MNIST/master/t10k-images-idx3-ubyte.gz to ../data/CustomMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 32.7MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ../data/CustomMNIST/raw/t10k-images-idx3-ubyte.gz to ../data/CustomMNIST/raw\n",
            "\n",
            "Downloading https://raw.githubusercontent.com/mkolod/MNIST/master/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://raw.githubusercontent.com/mkolod/MNIST/master/t10k-labels-idx1-ubyte.gz to ../data/CustomMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.21MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ../data/CustomMNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/CustomMNIST/raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 1/30 [00:03<01:55,  3.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 2/30 [00:07<01:48,  3.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, Loss: nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 3/30 [00:13<02:09,  4.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3, Loss: nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 4/30 [00:16<01:47,  4.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4, Loss: nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 5/30 [00:18<01:24,  3.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5, Loss: nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 6/30 [00:20<01:08,  2.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6, Loss: nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 23%|██▎       | 7/30 [00:22<01:01,  2.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7, Loss: nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 8/30 [00:25<01:00,  2.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8, Loss: nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 9/30 [00:27<00:53,  2.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9, Loss: nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 10/30 [00:30<00:47,  2.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10, Loss: nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 37%|███▋      | 11/30 [00:31<00:42,  2.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11, Loss: nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 12/30 [00:33<00:38,  2.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12, Loss: nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 43%|████▎     | 13/30 [00:35<00:35,  2.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13, Loss: nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 14/30 [00:38<00:35,  2.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14, Loss: nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 15/30 [00:40<00:32,  2.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15, Loss: nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 16/30 [00:42<00:30,  2.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16, Loss: nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 57%|█████▋    | 17/30 [00:44<00:28,  2.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17, Loss: nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 18/30 [00:46<00:26,  2.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18, Loss: nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 63%|██████▎   | 19/30 [00:49<00:24,  2.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19, Loss: nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 20/30 [00:51<00:23,  2.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20, Loss: nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 21/30 [00:53<00:19,  2.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21, Loss: nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 22/30 [00:55<00:16,  2.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22, Loss: nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 77%|███████▋  | 23/30 [00:57<00:14,  2.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23, Loss: nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 24/30 [01:00<00:13,  2.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24, Loss: nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 83%|████████▎ | 25/30 [01:03<00:12,  2.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25, Loss: nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 87%|████████▋ | 26/30 [01:05<00:09,  2.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26, Loss: nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 27/30 [01:07<00:06,  2.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27, Loss: nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 93%|█████████▎| 28/30 [01:09<00:04,  2.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28, Loss: nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 97%|█████████▋| 29/30 [01:11<00:02,  2.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29, Loss: nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [01:13<00:00,  2.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30, Loss: nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "    # Hyperparameters\n",
        "    embedding_dim = 32\n",
        "    num_heads = 4\n",
        "    num_layers = 4\n",
        "    dropout = 0.1\n",
        "    batch_size = 256\n",
        "    epochs = 30\n",
        "    lr = 1e-2\n",
        "    seq_len = 49\n",
        "    vocab_size = 256\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Prepare data\n",
        "    train_dataset = MNISTSequenceDataset(train=True)\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # Initialize model, optimizer, and loss function\n",
        "    model = SimpleGPT(vocab_size, seq_len, embedding_dim, num_heads, num_layers, dropout).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in tqdm.tqdm(range(1, epochs + 1)):\n",
        "        loss = train(model, train_dataloader, optimizer, criterion, device)\n",
        "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-U7CBONyFZRv"
      },
      "source": [
        "Generation Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lV7hypqGLDzm"
      },
      "outputs": [],
      "source": [
        "def generate_batch_no_cache(model, start_tokens, seq_len, device):\n",
        "    model.eval()\n",
        "    batch_size = start_tokens.size(0)\n",
        "\n",
        "    # Initialize input_ids with start tokens\n",
        "    input_ids = start_tokens.unsqueeze(1).to(device)\n",
        "    generated_tokens = input_ids\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(seq_len - 1):\n",
        "            # Pass the entire sequence each time\n",
        "            logits = model(generated_tokens)\n",
        "            next_token_logits = logits[:, -1, :]\n",
        "            probs = torch.softmax(next_token_logits, dim=-1)\n",
        "            next_tokens = torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "            # Append the generated token\n",
        "            generated_tokens = torch.cat([generated_tokens, next_tokens], dim=1)\n",
        "\n",
        "    return generated_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1h7v8ILlS8zu",
        "outputId": "8586f9d0-36e4-4884-b23c-ffd99650900f"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "probability tensor contains either `inf`, `nan` or element < 0",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-962b0a67e121>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Time without kv cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mgenerated_sequences_no_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_batch_no_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mtime_no_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-f2bcfc7e9284>\u001b[0m in \u001b[0;36mgenerate_batch_no_cache\u001b[0;34m(model, start_tokens, seq_len, device)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mnext_token_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_token_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mnext_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m# Append the generated token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: probability tensor contains either `inf`, `nan` or element < 0"
          ]
        }
      ],
      "source": [
        "\n",
        "import time\n",
        "\n",
        "num_samples = 20\n",
        "batch_size = num_samples\n",
        "start_tokens = torch.zeros(batch_size, dtype=torch.long)  # Start tokens for all sequences\n",
        "\n",
        "# Time without kv cache\n",
        "start_time = time.time()\n",
        "generated_sequences_no_cache = generate_batch_no_cache(model, start_tokens, seq_len, device).cpu().numpy()\n",
        "time_no_cache = time.time() - start_time\n",
        "\n",
        "dataset_images = []\n",
        "sampled_indices = np.random.randint(0, len(train_dataset), num_samples)\n",
        "for idx in sampled_indices:\n",
        "    img_seq = train_dataset[idx].numpy()\n",
        "    img = img_seq.reshape(7, 7)\n",
        "    dataset_images.append(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvDvQuIBWlzX"
      },
      "source": [
        "Let's check the generation quality, we should be able to get some how reasonable digit looks like this:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adEqZEMLUIze"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3Z_OqyziTC8E"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(2, 4, figsize=(10, 5))\n",
        "\n",
        "# Add row labels\n",
        "fig.text(-0.04, 0.7, 'Dataset Samples', va='center', ha='center', rotation='vertical', fontsize=12)\n",
        "fig.text(-0.04, 0.3, 'Generation Samples', va='center', ha='center', rotation='vertical', fontsize=12)\n",
        "\n",
        "for i in range(4):\n",
        "    # Display dataset image in the first row\n",
        "    axes[0, i].imshow(dataset_images[i], cmap='gray', interpolation='nearest')\n",
        "    axes[0, i].set_title(f'Sample {i+1}')\n",
        "    axes[0, i].axis('off')\n",
        "\n",
        "    # Display generated image in the second row\n",
        "    axes[1, i].imshow(generated_sequences_no_cache[i].reshape(7, 7), cmap='gray', interpolation='nearest')\n",
        "    axes[1, i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFH3mkqhFbqQ"
      },
      "source": [
        "# Follow-Up: Key-Value Caching Implementation\n",
        "\n",
        "\t•\tImplement a key-value caching mechanism to achieve at least a 2x speedup.\n",
        "\t•\tMaintain identical performance with the optimized mechanism."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_v-fVvfeLDzn"
      },
      "outputs": [],
      "source": [
        "def generate_batch(model, start_tokens, seq_len, device):\n",
        "    model.eval()\n",
        "    batch_size = start_tokens.size(0)\n",
        "\n",
        "    # Initialize input_ids with start tokens\n",
        "    input_ids = start_tokens.unsqueeze(1).to(device)  # Shape: (batch_size, 1)\n",
        "    generated_tokens = input_ids\n",
        "    #### code start here ###\n",
        "\n",
        "\n",
        "    ########################\n",
        "\n",
        "    return generated_tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHxwRAchGbV_"
      },
      "source": [
        "Let's test the runtime! You will measure how many time speed up by using kv cahe!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cPBamEh63FeZ"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "num_samples = 20\n",
        "batch_size = num_samples\n",
        "start_tokens = torch.zeros(batch_size, dtype=torch.long)  # Start tokens for all sequences\n",
        "\n",
        "# Time without kv cache\n",
        "start_time = time.time()\n",
        "generated_sequences_no_cache = generate_batch_no_cache(model, start_tokens, seq_len, device).cpu().numpy()\n",
        "time_no_cache = time.time() - start_time\n",
        "\n",
        "# Time with kv cache\n",
        "start_time = time.time()\n",
        "generated_sequences_with_cache = generate_batch(model, start_tokens, seq_len, device).cpu().numpy()\n",
        "time_with_cache = time.time() - start_time\n",
        "\n",
        "print(f\"Time without kv cache: {time_no_cache:.4f} seconds\")\n",
        "print(f\"Time with kv cache: {time_with_cache:.4f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsaAGiYCGkQJ"
      },
      "source": [
        "Let's check the generation quality!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "A9YbWPwuu17S"
      },
      "outputs": [],
      "source": [
        "dataset_images = []\n",
        "for idx in sampled_indices:\n",
        "    img_seq = train_dataset[idx].numpy()\n",
        "    img = img_seq.reshape(7, 7)\n",
        "    dataset_images.append(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-aB_b8rMyfjH"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(3, 5, figsize=(10, 5))\n",
        "\n",
        "for i in range(5):\n",
        "    # Display dataset image in the first row\n",
        "    axes[0, i].imshow(dataset_images[i], cmap='gray', interpolation='nearest')\n",
        "    axes[0, i].set_title(f'Sample {i+1}')\n",
        "    axes[0, i].axis('off')\n",
        "\n",
        "    # Display generated image in the second row\n",
        "    axes[1, i].imshow(generated_sequences_with_cache[i].reshape(7, 7), cmap='gray', interpolation='nearest')\n",
        "    axes[1, i].axis('off')\n",
        "\n",
        "    # Display generated image in the second row\n",
        "    axes[2, i].imshow(generated_sequences_no_cache[i].reshape(7, 7), cmap='gray', interpolation='nearest')\n",
        "    axes[2, i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHqEoiQeZlkK"
      },
      "source": [
        "# Follow-up questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NLnpDi_RZnka"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}